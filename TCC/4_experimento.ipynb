{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3942d4-4468-4cee-ba18-372e95772d94",
   "metadata": {},
   "source": [
    "# Previsão de séries temporais financeiras com memória de longo prazo\n",
    "## https://humboldt-wi.github.io/blog/research/information_systems_1718/06financialtime-series/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc23884a-a380-436c-936d-1972eff691a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>googLVL</th>\n",
       "      <th>volLVL</th>\n",
       "      <th>dif_highlowLVL</th>\n",
       "      <th>googRET</th>\n",
       "      <th>daxRET</th>\n",
       "      <th>y_closeRET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.0</td>\n",
       "      <td>94720.0</td>\n",
       "      <td>2.199996</td>\n",
       "      <td>-0.010929</td>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.031513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.0</td>\n",
       "      <td>97289.0</td>\n",
       "      <td>2.200005</td>\n",
       "      <td>-0.044951</td>\n",
       "      <td>-0.008962</td>\n",
       "      <td>-0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.0</td>\n",
       "      <td>68027.0</td>\n",
       "      <td>3.300003</td>\n",
       "      <td>-0.035091</td>\n",
       "      <td>-0.002549</td>\n",
       "      <td>0.023562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86.0</td>\n",
       "      <td>61603.0</td>\n",
       "      <td>3.449997</td>\n",
       "      <td>0.023530</td>\n",
       "      <td>-0.006265</td>\n",
       "      <td>-0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92.0</td>\n",
       "      <td>82983.0</td>\n",
       "      <td>2.699996</td>\n",
       "      <td>0.067441</td>\n",
       "      <td>-0.006739</td>\n",
       "      <td>-0.008174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   googLVL   volLVL  dif_highlowLVL   googRET    daxRET  y_closeRET\n",
       "0     91.0  94720.0        2.199996 -0.010929  0.014875    0.031513\n",
       "1     87.0  97289.0        2.200005 -0.044951 -0.008962   -0.005031\n",
       "2     84.0  68027.0        3.300003 -0.035091 -0.002549    0.023562\n",
       "3     86.0  61603.0        3.449997  0.023530 -0.006265   -0.009901\n",
       "4     92.0  82983.0        2.699996  0.067441 -0.006739   -0.008174"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# We read in the dataset\n",
    "data = pd.read_csv(\"final_df_VW.csv\")\n",
    " # delete column you dont want to use for training here!\n",
    "                      # We are deleteting date here.\n",
    "data.head()\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4be077e-bccd-4042-9f99-d00b6cf529f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to normalize\n",
    "def normalize(df):\n",
    "    \"\"\"\n",
    "        Uses minMax scaler on data to normalize. Important especially for Volume and google_lvl\n",
    "        @param df: data frame with all features\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(df)\n",
    "    df.dropna(inplace = True)\n",
    "    df = df.values\n",
    "    df = df.astype('float32')\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    norm = scaler.fit_transform(df)\n",
    "    return scaler, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b08371df-2d3b-4111-8742-a4444a64fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append with timesteps\n",
    "def createTimeSteps(df, lags=1):\n",
    "    \"\"\"\n",
    "        creates the amount of timesteps from the target and appends to df.\n",
    "        How many lags do we use to predict the target.\n",
    "        @param df: data frame with all features\n",
    "        @param lags: number of lags from the target that are appended\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(df)\n",
    "    columns = list()\n",
    "    for i in range(lags, 0, -1):\n",
    "        columns.append(df.shift(i))\n",
    "    columns.append(df) #add original\n",
    "    # combine\n",
    "    output = pd.concat(columns, axis=1)\n",
    "    # replace rows with NaN values\n",
    "    output.fillna(0, inplace = True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adbfcf67-5cac-48e1-9bf0-773377947fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything prepared...\n",
    "scaler, normalized_data = normalize(data)\n",
    "\n",
    "BATCH_SIZE = 1 # batch size during training\n",
    "TS = 14 # length of Sequence we use for our samples (7 = week, 30 = month)\n",
    "FEATURES = 6 # number of features in data set\n",
    "TRAINING_DAYS = 1250 # Training/Test split for data\n",
    "\n",
    "full_df = createTimeSteps(normalized_data, TS)\n",
    "# display(full_df)\n",
    "full_df = full_df.values # Training vs Test\n",
    "\n",
    "train = full_df[:TRAINING_DAYS, :]\n",
    "test = full_df[TRAINING_DAYS:, :]\n",
    "\n",
    "input_var = int(TS*FEATURES) # Every feature has as many columns as defined timestep\n",
    "target = -1 # Our Volkswagen AG stock price is the last column of our dataset\n",
    "X_train, y_train = train[:, :input_var], train[:, target]\n",
    "X_test, y_test = test[:, :input_var], test[:, target]\n",
    "\n",
    "X_train = X_train.reshape(TRAINING_DAYS, TS, FEATURES)\n",
    "X_test = X_test.reshape(X_test.shape[0], TS, FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe4962c-feb9-4d16-ac69-be671135b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our first very easy model\n",
    "def helloModel(timesteps, features, batch_size=1):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(16, input_shape=(timesteps, features)))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))  \n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b0d2236-6efc-450d-8d56-9976fcc69ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "def fitting(model, X, y, val_X, val_y, epochs, batch_size=1, state_config=False, sf=False):\n",
    "    \"\"\"\n",
    "        fits the model to the data via keras API.\n",
    "        @param model: before designed model setup\n",
    "        @param X: correctly reshaped input data\n",
    "        @param y: correctly reshaped target\n",
    "        @param val_X, val_y: correctly reshaped test data\n",
    "        @param epochs: number of epochs to repeat training\n",
    "        @param batch_size: number of rows after the weights of the network are updated\n",
    "        @param state_config: True/False - if true, model is trained with stateful mode and\n",
    "        states are resetted every epoch\n",
    "        @param sf: True/False - shuffle mode. If stateless, this makes sense to increase\n",
    "        generalization of the model\n",
    "    \"\"\"\n",
    "    if state_config:\n",
    "        training_mse = list()\n",
    "        val_mse = list()\n",
    "        for i in range(epochs):\n",
    "            model.reset_states()\n",
    "            result = model.fit(X, y, batch_size=batch_size, epochs=1, validation_data=(val_X, val_y), shuffle=sf)\n",
    "            training_mse.append(result.history['mse'])\n",
    "            val_mse.append(result.history['val_mse'])\n",
    "    else:\n",
    "        result = model.fit(X, y, batch_size=batch_size,\n",
    "                        epochs=epochs, validation_data=(val_X, val_y), shuffle=sf)\n",
    "        training_mse = result.history['mse']\n",
    "        val_mse = result.history['val_mse']\n",
    "\n",
    "\n",
    "    return result, training_mse, val_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba62eea-c572-405c-a19a-bb60426e1718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1250/1250 [==============================] - 7s 4ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 2/30\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 3/30\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 4/30\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 5/30\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 6/30\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 7/30\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 8/30\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 9/30\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 10/30\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 11/30\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 12/30\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 13/30\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 14/30\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 15/30\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 16/30\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 17/30\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 18/30\n",
      "1028/1250 [=======================>......] - ETA: 0s - loss: 0.0204 - mse: 0.0204"
     ]
    }
   ],
   "source": [
    "# Almost forgot... your libraries\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout, TimeDistributed, RepeatVector\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from pandas import read_csv, DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Our new CONSTANTS\n",
    "EPOCHS = 30 # number of training Epochs\n",
    "STATEFUL = True # stateless/stateful\n",
    "SF = False # activate shuffle\n",
    "RETURN_SEQ = False # many to many prediction (outputs results of every TS)\n",
    "\n",
    "# Choose a model\n",
    "model =  helloModel(TS, FEATURES, batch_size=BATCH_SIZE)\n",
    "# Fit the model\n",
    "result, training_mse, val_mse = fitting(model, X_train, y_train, X_test, y_test, EPOCHS, batch_size=BATCH_SIZE)\n",
    "# Predict the model\n",
    "yhat = model.predict(X_test, batch_size = BATCH_SIZE)\n",
    "print(yhat.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Plot the model\n",
    "plt.plot(y_test, label='y')\n",
    "plt.plot(yhat, label='yhat')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(training_mse, label='Training: MSE')\n",
    "plt.plot(val_mse, label='Test: MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b215c31-e3b8-47e7-8e72-b4ceab469788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4632a967-a0ea-4c3c-b7d2-620ad17c0435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
