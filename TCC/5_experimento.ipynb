{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3942d4-4468-4cee-ba18-372e95772d94",
   "metadata": {},
   "source": [
    "# Previsão de séries temporais financeiras com memória de longo prazo\n",
    "## https://humboldt-wi.github.io/blog/research/information_systems_1718/06financialtime-series/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc23884a-a380-436c-936d-1972eff691a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>googLVL</th>\n",
       "      <th>volLVL</th>\n",
       "      <th>dif_highlowLVL</th>\n",
       "      <th>googRET</th>\n",
       "      <th>daxRET</th>\n",
       "      <th>y_closeRET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.0</td>\n",
       "      <td>94720.0</td>\n",
       "      <td>2.199996</td>\n",
       "      <td>-0.010929</td>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.031513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.0</td>\n",
       "      <td>97289.0</td>\n",
       "      <td>2.200005</td>\n",
       "      <td>-0.044951</td>\n",
       "      <td>-0.008962</td>\n",
       "      <td>-0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.0</td>\n",
       "      <td>68027.0</td>\n",
       "      <td>3.300003</td>\n",
       "      <td>-0.035091</td>\n",
       "      <td>-0.002549</td>\n",
       "      <td>0.023562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86.0</td>\n",
       "      <td>61603.0</td>\n",
       "      <td>3.449997</td>\n",
       "      <td>0.023530</td>\n",
       "      <td>-0.006265</td>\n",
       "      <td>-0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92.0</td>\n",
       "      <td>82983.0</td>\n",
       "      <td>2.699996</td>\n",
       "      <td>0.067441</td>\n",
       "      <td>-0.006739</td>\n",
       "      <td>-0.008174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   googLVL   volLVL  dif_highlowLVL   googRET    daxRET  y_closeRET\n",
       "0     91.0  94720.0        2.199996 -0.010929  0.014875    0.031513\n",
       "1     87.0  97289.0        2.200005 -0.044951 -0.008962   -0.005031\n",
       "2     84.0  68027.0        3.300003 -0.035091 -0.002549    0.023562\n",
       "3     86.0  61603.0        3.449997  0.023530 -0.006265   -0.009901\n",
       "4     92.0  82983.0        2.699996  0.067441 -0.006739   -0.008174"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# We read in the dataset\n",
    "data = pd.read_csv(\"final_df_VW.csv\")\n",
    " # delete column you dont want to use for training here!\n",
    "                      # We are deleteting date here.\n",
    "data.head()\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4be077e-bccd-4042-9f99-d00b6cf529f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to normalize\n",
    "def normalize(df):\n",
    "    \"\"\"\n",
    "        Uses minMax scaler on data to normalize. Important especially for Volume and google_lvl\n",
    "        @param df: data frame with all features\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(df)\n",
    "    df.dropna(inplace = True)\n",
    "    df = df.values\n",
    "    df = df.astype('float32')\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    norm = scaler.fit_transform(df)\n",
    "    return scaler, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b08371df-2d3b-4111-8742-a4444a64fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append with timesteps\n",
    "def createTimeSteps(df, lags=1):\n",
    "    \"\"\"\n",
    "        creates the amount of timesteps from the target and appends to df.\n",
    "        How many lags do we use to predict the target.\n",
    "        @param df: data frame with all features\n",
    "        @param lags: number of lags from the target that are appended\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(df)\n",
    "    columns = list()\n",
    "    for i in range(lags, 0, -1):\n",
    "        columns.append(df.shift(i))\n",
    "    columns.append(df) #add original\n",
    "    # combine\n",
    "    output = pd.concat(columns, axis=1)\n",
    "    # replace rows with NaN values\n",
    "    output.fillna(0, inplace = True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adbfcf67-5cac-48e1-9bf0-773377947fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.75242233 -0.94865036 -0.90636706 -0.48040822  0.43544805  0.6370585 ]\n",
      " [-0.79927146 -0.94696146 -0.90636635 -0.581046    0.03546742  0.36449647]\n",
      " [-0.8344083  -0.96619934 -0.8239695  -0.55188     0.14307705  0.57775795]\n",
      " ...\n",
      " [-0.74728394 -0.9756204  -0.898877    0.06025165  0.18229441  0.3976298 ]\n",
      " [-0.76983035 -0.9871866  -0.9775278  -0.5110185   0.06980572  0.40640754]\n",
      " [-0.80365    -0.98046106 -0.8913859  -0.5450722   0.10511929  0.34476423]]\n",
      "[[ 0.          0.          0.         ... -0.48040822  0.43544805\n",
      "   0.6370585 ]\n",
      " [ 0.          0.          0.         ... -0.581046    0.03546742\n",
      "   0.36449647]\n",
      " [ 0.          0.          0.         ... -0.55188     0.14307705\n",
      "   0.57775795]\n",
      " ...\n",
      " [-0.8712893  -0.94494045 -0.9400746  ...  0.06025165  0.18229441\n",
      "   0.3976298 ]\n",
      " [-0.905109   -0.9482415  -0.94756573 ... -0.5110185   0.06980572\n",
      "   0.40640754]\n",
      " [-0.86001617 -0.9362709  -0.7865163  ... -0.5450722   0.10511929\n",
      "   0.34476423]]\n"
     ]
    }
   ],
   "source": [
    "# Everything prepared...\n",
    "scaler, normalized_data = normalize(data)\n",
    "print(normalized_data)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1 # batch size during training\n",
    "TS = 7 # length of Sequence we use for our samples (7 = week, 30 = month)\n",
    "FEATURES = 6 # number of features in data set\n",
    "TRAINING_DAYS = 1250 # Training/Test split for data\n",
    "\n",
    "full_df = createTimeSteps(normalized_data, TS)\n",
    "full_df = full_df.values # Training vs Test\n",
    "print(full_df)\n",
    "\n",
    "train = full_df[:TRAINING_DAYS, :]\n",
    "\n",
    "test = full_df[TRAINING_DAYS:, :]\n",
    "\n",
    "input_var = int(TS*FEATURES) # Every feature has as many columns as defined timestep\n",
    "target = -1 # Our Volkswagen AG stock price is the last column of our dataset\n",
    "X_train, y_train = train[:, :input_var], train[:, target]\n",
    "X_test, y_test = test[:, :input_var], test[:, target]\n",
    "\n",
    "X_train = X_train.reshape(TRAINING_DAYS, TS, FEATURES)\n",
    "X_test = X_test.reshape(X_test.shape[0], TS, FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe4962c-feb9-4d16-ac69-be671135b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our first very easy model\n",
    "def helloModel(timesteps, features, batch_size=1):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(16, input_shape=(timesteps, features)))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))  \n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b0d2236-6efc-450d-8d56-9976fcc69ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "def fitting(model, X, y, val_X, val_y, epochs, batch_size=1, state_config=False, sf=False):\n",
    "    \"\"\"\n",
    "        fits the model to the data via keras API.\n",
    "        @param model: before designed model setup\n",
    "        @param X: correctly reshaped input data\n",
    "        @param y: correctly reshaped target\n",
    "        @param val_X, val_y: correctly reshaped test data\n",
    "        @param epochs: number of epochs to repeat training\n",
    "        @param batch_size: number of rows after the weights of the network are updated\n",
    "        @param state_config: True/False - if true, model is trained with stateful mode and\n",
    "        states are resetted every epoch\n",
    "        @param sf: True/False - shuffle mode. If stateless, this makes sense to increase\n",
    "        generalization of the model\n",
    "    \"\"\"\n",
    "    if state_config:\n",
    "        training_mse = list()\n",
    "        val_mse = list()\n",
    "        for i in range(epochs):\n",
    "            model.reset_states()\n",
    "            result = model.fit(X, y, batch_size=batch_size, epochs=1, validation_data=(val_X, val_y), shuffle=sf)\n",
    "            training_mse.append(result.history['mse'])\n",
    "            val_mse.append(result.history['val_mse'])\n",
    "    else:\n",
    "        result = model.fit(X, y, batch_size=batch_size,\n",
    "                        epochs=epochs, validation_data=(val_X, val_y), shuffle=sf)\n",
    "        training_mse = result.history['mse']\n",
    "        val_mse = result.history['val_mse']\n",
    "\n",
    "\n",
    "    return result, training_mse, val_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba62eea-c572-405c-a19a-bb60426e1718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  12/1250 [..............................] - ETA: 6s - loss: 0.0638 - mse: 0.0638   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8b7faaaac993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mhelloModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFEATURES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m# Predict the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-521613ad393a>\u001b[0m in \u001b[0;36mfitting\u001b[0;34m(model, X, y, val_X, val_y, epochs, batch_size, state_config, sf)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mval_mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         result = model.fit(X, y, batch_size=batch_size,\n\u001b[0m\u001b[1;32m     26\u001b[0m                         epochs=epochs, validation_data=(val_X, val_y), shuffle=sf)\n\u001b[1;32m     27\u001b[0m         \u001b[0mtraining_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 _r=1):\n\u001b[1;32m   1181\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    938\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3012\u001b[0m       (graph_function,\n\u001b[1;32m   3013\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3014\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3015\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1956\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1957\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1958\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1959\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    593\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Almost forgot... your libraries\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout, TimeDistributed, RepeatVector\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from pandas import read_csv, DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Our new CONSTANTS\n",
    "EPOCHS = 30 # number of training Epochs\n",
    "STATEFUL = True # stateless/stateful\n",
    "SF = False # activate shuffle\n",
    "RETURN_SEQ = False # many to many prediction (outputs results of every TS)\n",
    "\n",
    "# Choose a model\n",
    "model =  helloModel(TS, FEATURES, batch_size=BATCH_SIZE)\n",
    "# Fit the model\n",
    "result, training_mse, val_mse = fitting(model, X_train, y_train, X_test, y_test, EPOCHS, batch_size=BATCH_SIZE)\n",
    "# Predict the model\n",
    "yhat = model.predict(X_test, batch_size = BATCH_SIZE)\n",
    "print(yhat.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Plot the model\n",
    "plt.plot(y_test, label='y')\n",
    "plt.plot(yhat, label='yhat')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(training_mse, label='Training: MSE')\n",
    "plt.plot(val_mse, label='Test: MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b215c31-e3b8-47e7-8e72-b4ceab469788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4632a967-a0ea-4c3c-b7d2-620ad17c0435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
